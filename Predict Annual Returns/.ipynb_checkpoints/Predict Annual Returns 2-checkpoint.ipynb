{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data: (9366, 18)\n",
      "Shape of testing Data: (4801, 17)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of train data:', train.shape)\n",
    "print('Shape of testing Data:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "null_cols = [key for key, value in train.isnull().any().iteritems() if value==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null values:\n",
      "desk_id = 3665\n",
      "sold = 2\n",
      "libor_rate = 474\n",
      "bought = 2\n",
      "indicator_code = 5699\n",
      "hedge_value = 5701\n",
      "status = 3084\n"
     ]
    }
   ],
   "source": [
    "# Count Null Values\n",
    "null_list = train.isnull()\n",
    "print ('Number of Null values:')\n",
    "for col in null_cols:\n",
    "    print ('{} = {}'.format(col, sum(null_list[col])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Start Date\n",
    "train['start_year'] = train['start_date'].apply(lambda x: int(str(x)[0:4]))\n",
    "train['start_month'] = train['start_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "train['start_date'] = train['start_date'].apply(lambda x: int(str(x)[6:8]))\n",
    "\n",
    "test['start_year'] = test['start_date'].apply(lambda x: int(str(x)[0:4]))\n",
    "test['start_month'] = test['start_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "test['start_date'] = test['start_date'].apply(lambda x: int(str(x)[6:8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Creation Date\n",
    "train['create_year'] = train['creation_date'].apply(lambda x: int(str(x)[0:4]))\n",
    "train['create_month'] = train['creation_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "train['create_date'] = train['creation_date'].apply(lambda x: int(str(x)[6:8]))\n",
    "\n",
    "test['create_year'] = test['creation_date'].apply(lambda x: int(str(x)[0:4]))\n",
    "test['create_month'] = test['creation_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "test['create_date'] = test['creation_date'].apply(lambda x: int(str(x)[6:8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Sell date\n",
    "train['sell_year'] = train['sell_date'].apply(lambda x: int(str(x)[0:4]))\n",
    "train['sell_month'] = train['sell_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "train['sell_date'] = train['sell_date'].apply(lambda x: int(str(x)[6:8]))\n",
    "\n",
    "test['sell_year'] = test['sell_date'].apply(lambda x: int(str(x)[0:4]))\n",
    "test['sell_month'] = test['sell_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "test['sell_date'] = test['sell_date'].apply(lambda x: int(str(x)[6:8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = list(train.columns)\n",
    "cols.remove('portfolio_id')\n",
    "cols.remove('return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 1038.66it/s]\n"
     ]
    }
   ],
   "source": [
    "num_cols = []\n",
    "for col in tqdm(cols):\n",
    "    if train[col].dtype == 'int64' or train[col].dtype == 'float64':\n",
    "        num_cols.append(col)\n",
    "        train[col].fillna(train[col].mean(), inplace =True)\n",
    "        test[col].fillna(test[col].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()\n",
    "train[num_cols] = scalar.fit_transform(train[num_cols])\n",
    "test[num_cols] = scalar.fit_transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 102.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in tqdm(cols):\n",
    "    if train[col].dtype == 'object':\n",
    "        train[col] = train[col].apply(str)\n",
    "        test[col] = test[col].apply(str)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        train_vals = list(train[col].unique())\n",
    "        test_vals = list(test[col].unique())\n",
    "        le.fit(train_vals + test_vals)\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### K-fold CV with Out-of-Fold Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def r2_score_lgb(pred, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    score = r2_score(y_true=y, y_pred=pred)\n",
    "    return 'r2-score', score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_sklearn(clf, x_train, y_train, x_test, kf, scale=False, verbose=True):\n",
    "    # Intialise the size of out of fold train on test prediction\n",
    "    train_pred = np.zeros((x_train.shape[0]))\n",
    "    test_pred = np.zeros((x_test.shape[0]))\n",
    "    \n",
    "    # use k-fold object to geerate the required folds\n",
    "    for i, (train_index,test_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        # generate training and validation folds\n",
    "        x_train_kf, x_val_kf = x_train.loc[train_index, :], x_train.loc[test_index, :]\n",
    "        y_train_kf, y_val_kf = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        x_train_kf_values = x_train_kf.values\n",
    "        x_val_kf_values = x_val_kf.values\n",
    "        x_test_values = x_test.values\n",
    "        \n",
    "        # fit the input classifier and perform prediction\n",
    "        clf.fit(x_train_kf_values, y_train_kf.values)\n",
    "        val_pred = clf.predict(x_val_kf_values)[:,1]\n",
    "        train_pred[test_index] += val_pred\n",
    "        \n",
    "        y_test_preds = clf.predict(x_test_values)[:,1]\n",
    "        test_pred += y_test_preds\n",
    "        \n",
    "        fold_r2_score = r2_score(y_val_kf.values, val_pred)\n",
    "        \n",
    "        if verbose:\n",
    "            print('fold cv {} R2_score is{:.6f}'.format(i, fold_r2_score))\n",
    "    \n",
    "    test_pred /= kf.n_splits\n",
    "    \n",
    "    cv_r2_score = r2_score(y_train, train_pred)\n",
    "    if verbose:\n",
    "        print('cv R2_score is {:.6f}'.format(cv_r2_score))\n",
    "    \n",
    "    return cv_r2_score, train_pred, test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost K-Fold & OOF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probability_to_rank(prediction, scaler = 1):\n",
    "    pred_df = pd.DataFrame(columns=['probability'])\n",
    "    pred_df['probability'] = prediction\n",
    "    pred_df['rank'] = pred_df['probability'].rank()/len(prediction)*scaler\n",
    "    return pred_df['rank'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_xgb(params, x_train, y_train, x_test, kf, cat_cols=[], verbose=True, verbose_eval=50, num_boost_round=4000):\n",
    "    train_pred = np.zeros((x_train.shape[0]))\n",
    "    test_pred = np.zeros((x_test.shape[0]))\n",
    "    \n",
    "    # Use the k-fold object to enumerate indexes for each training and validation fold\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        x_train_kf, x_val_kf = x_train.loc[train_index, :], x_train.loc[val_index, :]\n",
    "        y_train_kf, y_val_kf = y_train[train_index], y_train_kf[val_index]\n",
    "        x_test_kf = x_test.copy()\n",
    "        \n",
    "        d_train_kf = xgb.DMatrix(x_train_kf, label=y_train_kf)\n",
    "        d_val_kf = xgb.DMatrix(x_val_kf, label=y_val_kf)\n",
    "        d_test = xgb.DMatrix(x_test_kf)\n",
    "        \n",
    "        bst = xgb.train(params, d_train_kf, num_boost_round=num_boost_round, evals=[(d_train_kf, 'train'),(d_val_kf, 'val')], verbose_eval=verbose_eval, early_stopping_rounds=50)\n",
    "        \n",
    "        val_pred= bst.predict(d_val_kf, ntree_limit=bst.best_ntree_limit)\n",
    "        \n",
    "        train_pred[val_index] += val_pred\n",
    "        test_pred += bst.predict(d_test)\n",
    "         \n",
    "        fold_r2_score = r2_score(y_val_kf.values, val_pred)\n",
    "        \n",
    "        if verbose:\n",
    "            print('fold cv {} R2_score is{:.6f}'.format(i, fold_r2_score))\n",
    "    \n",
    "    test_pred /= kf.n_splits\n",
    "    \n",
    "    cv_r2_score = r2_score(y_train, train_pred)\n",
    "    if verbose:\n",
    "        print('cv R2_score is {:.6f}'.format(cv_r2_score))\n",
    "    \n",
    "    return cv_r2_score, train_pred, test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM K-Fold & OOF Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_lgb(params, x_train, y_train, x_test, kf, cat_cols=[], verbose=True, verbose_eval=50, num_boost_round=4000):\n",
    "    train_pred = np.zeros((x_train.shape[0]))\n",
    "    test_pred = np.zeros((x_test.shape[0]))\n",
    "    \n",
    "    if len(cat_cols)==0: use_cat = False\n",
    "    # Use the k-fold object to enumerate indexes for each training and validation fold\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        x_train_kf, x_val_kf = x_train.loc[train_index, :], x_train.loc[val_index, :]\n",
    "        y_train_kf, y_val_kf = y_train[train_index], y_train_kf[val_index]\n",
    "        x_test_kf = x_test.copy()\n",
    "        \n",
    "        if use_cat:\n",
    "            lgb_train = lgb.Dataset(x_train_kf, label=y_train_kf, categorical_feature=cat_cols)\n",
    "            lgb_val = lgb.Dataset(x_val_kf, label=y_val_kf, reference=lgb_train, categorical_feature=cat_cols)\n",
    "        else:\n",
    "            lgb_train = lgb.Dataset(x_train_kf, label=y_train_kf)\n",
    "            lgb_val = lgb.Dataset(x_val_kf, label=y_val_kf, reference=lgb_train)\n",
    "            \n",
    "        bst = lgb.train(params, lgb_train, num_boost_round=num_boost_round, valid_sets=lgb_val, verbose_eval=verbose_eval, early_stopping_rounds=50)\n",
    "        \n",
    "        val_pred= bst.predict(x_val_kf)\n",
    "        \n",
    "        train_pred[val_index] += val_pred\n",
    "        test_pred += bst.predict(x_test)\n",
    "         \n",
    "        fold_r2_score = r2_score(y_val_kf.values, val_pred)\n",
    "        \n",
    "        if verbose:\n",
    "            print('fold cv {} R2_score is{:.6f}'.format(i, fold_r2_score))\n",
    "    \n",
    "    test_pred /= kf.n_splits\n",
    "    \n",
    "    cv_r2_score = r2_score(y_train, train_pred)\n",
    "    if verbose:\n",
    "        print('cv R2_score is {:.6f}'.format(cv_r2_score))\n",
    "    \n",
    "    return cv_r2_score, train_pred, test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Level 1 OOF predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_cols = ['portfolio_id', 'return']\n",
    "y_train = train['return']\n",
    "x_train = train.drop(drop_cols, axis=1)\n",
    "x_test  = test.drop(['portfolio_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
